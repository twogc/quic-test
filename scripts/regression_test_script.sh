#!/bin/bash

# Regression Test Script for QUIC Performance Comparison
# ====================================================

set -e

# Ğ¦Ğ²ĞµÑ‚Ğ° Ğ´Ğ»Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ°
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ñ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼
print_color() {
    local color=$1
    local message=$2
    echo -e "${color}${message}${NC}"
}

# ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¾Ğ²
ALGORITHMS=("cubic" "bbrv2")            # ĞĞ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñ‹ Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
TEST_DURATION=60                         # Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ° Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
OUTPUT_DIR="./regression-results"        # Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
METRICS_INTERVAL=1                       # Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» ÑĞ±Ğ¾Ñ€Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
check_dependencies() {
    print_color $BLUE "ğŸ” Checking dependencies..."
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ quic-test-experimental
    if [ ! -f "./quic-test-experimental" ]; then
        print_color $YELLOW "âš ï¸  quic-test-experimental not found, building..."
        go build -o quic-test-experimental ./cmd/experimental/
    fi
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ jq Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° JSON
    if ! command -v jq &> /dev/null; then
        print_color $YELLOW "âš ï¸  jq not found, installing..."
        sudo apt-get update && sudo apt-get install -y jq
    fi
    
    print_color $GREEN "âœ… Dependencies OK"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ñ‚ĞµÑÑ‚Ğ° Ñ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ¼
run_regression_test() {
    local algorithm=$1
    local test_id="regression_${algorithm}"
    local test_dir="${OUTPUT_DIR}/${test_id}"
    
    print_color $YELLOW "ğŸ”„ Running regression test: Algorithm=${algorithm}"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ°
    mkdir -p "$test_dir"
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞµÑ€Ğ²ĞµÑ€
    print_color $BLUE "ğŸš€ Starting server with ${algorithm}..."
    nohup ./quic-test-experimental \
        --mode server \
        --cc $algorithm \
        --qlog "${test_dir}/server-qlog" \
        --verbose \
        --metrics-interval ${METRICS_INTERVAL}s \
        --sla-p95-rtt 100 \
        --sla-loss 5 \
        --sla-goodput 10 \
        > "${test_dir}/server.log" 2>&1 &
    
    local server_pid=$!
    print_color $GREEN "âœ… Server started (PID: $server_pid)"
    
    # Ğ–Ğ´ĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° ÑĞµÑ€Ğ²ĞµÑ€Ğ°
    sleep 5
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ»Ğ¸ĞµĞ½Ñ‚
    print_color $BLUE "ğŸ”— Starting client..."
    timeout ${TEST_DURATION}s ./quic-test-experimental \
        --mode client \
        --addr 127.0.0.1:9000 \
        --cc $algorithm \
        --qlog "${test_dir}/client-qlog" \
        --duration ${TEST_DURATION}s \
        --connections 1 \
        --streams 1 \
        --rate 100 \
        --packet-size 1200 \
        --verbose \
        > "${test_dir}/client.log" 2>&1 &
    
    local client_pid=$!
    
    # Ğ–Ğ´ĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°
    wait $client_pid 2>/dev/null || true
    
    # ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞµÑ€Ğ²ĞµÑ€
    kill $server_pid 2>/dev/null || true
    wait $server_pid 2>/dev/null || true
    
    # ĞŸĞ°ÑƒĞ·Ğ° Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ‚ĞµÑÑ‚Ğ°Ğ¼Ğ¸
    sleep 3
    
    print_color $GREEN "âœ… Regression test completed: ${test_id}"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¸Ğ· Ğ»Ğ¾Ğ³Ğ¾Ğ²
extract_metrics() {
    local test_dir=$1
    local algorithm=$2
    
    print_color $BLUE "ğŸ“Š Extracting metrics for ${algorithm}..."
    
    local metrics_file="${test_dir}/metrics.json"
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸Ğ· Ğ»Ğ¾Ğ³Ğ¾Ğ²
    cat > "$metrics_file" << EOF
{
  "algorithm": "${algorithm}",
  "test_duration": ${TEST_DURATION},
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "server_metrics": {
    "connections_accepted": $(grep -c "New QUIC connection accepted" "${test_dir}/server.log" 2>/dev/null || echo "0"),
    "packets_sent": $(grep -o "packets sent: [0-9]*" "${test_dir}/server.log" | grep -o "[0-9]*" | tail -1 || echo "0"),
    "bytes_sent": $(grep -o "bytes sent: [0-9]*" "${test_dir}/server.log" | grep -o "[0-9]*" | tail -1 || echo "0"),
    "errors": $(grep -c "ERROR" "${test_dir}/server.log" 2>/dev/null || echo "0"),
    "warnings": $(grep -c "WARN" "${test_dir}/server.log" 2>/dev/null || echo "0")
  },
  "client_metrics": {
    "connection_established": $(grep -c "connection established" "${test_dir}/client.log" 2>/dev/null || echo "0"),
    "packets_received": $(grep -o "packets received: [0-9]*" "${test_dir}/client.log" | grep -o "[0-9]*" | tail -1 || echo "0"),
    "bytes_received": $(grep -o "bytes received: [0-9]*" "${test_dir}/client.log" | grep -o "[0-9]*" | tail -1 || echo "0"),
    "errors": $(grep -c "ERROR" "${test_dir}/client.log" 2>/dev/null || echo "0"),
    "warnings": $(grep -c "WARN" "${test_dir}/client.log" 2>/dev/null || echo "0")
  },
  "performance_metrics": {
    "throughput_mbps": $(echo "scale=2; $(grep -o "bytes received: [0-9]*" "${test_dir}/client.log" | grep -o "[0-9]*" | tail -1 || echo "0") * 8 / 1000000 / ${TEST_DURATION}" | bc 2>/dev/null || echo "0"),
    "packet_loss_rate": $(echo "scale=4; $(grep -o "packets lost: [0-9]*" "${test_dir}/client.log" | grep -o "[0-9]*" | tail -1 || echo "0") / $(grep -o "packets sent: [0-9]*" "${test_dir}/client.log" | grep -o "[0-9]*" | tail -1 || echo "1") * 100" | bc 2>/dev/null || echo "0"),
    "avg_latency_ms": $(echo "scale=2; $(grep -o "avg latency: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0"),
    "max_latency_ms": $(echo "scale=2; $(grep -o "max latency: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0"),
    "min_latency_ms": $(echo "scale=2; $(grep -o "min latency: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0")
  },
  "sla_compliance": {
    "p95_rtt_ms": $(echo "scale=2; $(grep -o "p95 rtt: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0"),
    "loss_rate_percent": $(echo "scale=2; $(grep -o "loss rate: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0"),
    "goodput_mbps": $(echo "scale=2; $(grep -o "goodput: [0-9.]*" "${test_dir}/client.log" | grep -o "[0-9.]*" | tail -1 || echo "0")" | bc 2>/dev/null || echo "0")
  }
}
EOF
    
    print_color $GREEN "âœ… Metrics extracted: $metrics_file"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
compare_results() {
    print_color $BLUE "ğŸ“Š Comparing regression test results..."
    
    local comparison_file="${OUTPUT_DIR}/regression_comparison.json"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ
    cat > "$comparison_file" << EOF
{
  "comparison_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "test_duration": ${TEST_DURATION},
  "algorithms_compared": ["cubic", "bbrv2"],
  "comparison_results": {
    "cubic": $(cat "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "{}"),
    "bbrv2": $(cat "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "{}")
  }
}
EOF
    
    # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ
    local cubic_throughput=$(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")
    local bbrv2_throughput=$(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")
    
    local throughput_improvement=$(echo "scale=2; ($bbrv2_throughput - $cubic_throughput) / $cubic_throughput * 100" | bc 2>/dev/null || echo "0")
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹
    cat >> "$comparison_file" << EOF
,
  "performance_improvements": {
    "throughput_improvement_percent": ${throughput_improvement},
    "latency_improvement_percent": $(echo "scale=2; ($(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "0"),
    "loss_rate_improvement_percent": $(echo "scale=2; ($(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "0")
  }
}
EOF
    
    print_color $GREEN "âœ… Comparison completed: $comparison_file"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
generate_report() {
    print_color $BLUE "ğŸ“‹ Generating regression test report..."
    
    local report_file="${OUTPUT_DIR}/regression_test_report.md"
    
    cat > "$report_file" << EOF
# QUIC Regression Test Report

**Generated:** $(date)
**Test Duration:** ${TEST_DURATION}s per algorithm
**Algorithms Compared:** CUBIC vs BBRv2

## Test Configuration

- **Test Duration:** ${TEST_DURATION} seconds per algorithm
- **Connections:** 1
- **Streams:** 1
- **Packet Rate:** 100 pps
- **Packet Size:** 1200 bytes
- **SLA Gates:** P95 RTT < 100ms, Loss < 5%, Goodput > 10 Mbps

## Test Results

### CUBIC Algorithm
EOF
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ CUBIC
    if [ -f "${OUTPUT_DIR}/regression_cubic/metrics.json" ]; then
        cat >> "$report_file" << EOF
- **Throughput:** $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json") Mbps
- **Average Latency:** $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json") ms
- **Packet Loss Rate:** $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json")%
- **P95 RTT:** $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json") ms
- **Goodput:** $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json") Mbps
- **Errors:** $(jq -r '.server_metrics.errors + .client_metrics.errors' "${OUTPUT_DIR}/regression_cubic/metrics.json")
EOF
    else
        echo "- **Status:** Test failed or not completed" >> "$report_file"
    fi
    
    cat >> "$report_file" << EOF

### BBRv2 Algorithm
EOF
    
    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ BBRv2
    if [ -f "${OUTPUT_DIR}/regression_bbrv2/metrics.json" ]; then
        cat >> "$report_file" << EOF
- **Throughput:** $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json") Mbps
- **Average Latency:** $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json") ms
- **Packet Loss Rate:** $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_bbrv2/metrics.json")%
- **P95 RTT:** $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json") ms
- **Goodput:** $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json") Mbps
- **Errors:** $(jq -r '.server_metrics.errors + .client_metrics.errors' "${OUTPUT_DIR}/regression_bbrv2/metrics.json")
EOF
    else
        echo "- **Status:** Test failed or not completed" >> "$report_file"
    fi
    
    cat >> "$report_file" << EOF

## Performance Comparison

| Metric | CUBIC | BBRv2 | Improvement |
|--------|-------|-------|-------------|
| Throughput (Mbps) | $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "N/A") | $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "N/A") | $(echo "scale=1; ($(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "N/A")% |
| Avg Latency (ms) | $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "N/A") | $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "N/A") | $(echo "scale=1; ($(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.performance_metrics.avg_latency_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "N/A")% |
| Loss Rate (%) | $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "N/A") | $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "N/A") | $(echo "scale=1; ($(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.performance_metrics.packet_loss_rate' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "N/A")% |
| P95 RTT (ms) | $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "N/A") | $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "N/A") | $(echo "scale=1; ($(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "N/A")% |
| Goodput (Mbps) | $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "N/A") | $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "N/A") | $(echo "scale=1; ($(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0") - $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")) / $(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "1") * 100" | bc 2>/dev/null || echo "N/A")% |

## SLA Compliance

### CUBIC SLA Compliance
- **P95 RTT < 100ms:** $(if [ "$(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")" -lt 100 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)
- **Loss Rate < 5%:** $(if [ "$(jq -r '.sla_compliance.loss_rate_percent' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")" -lt 5 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)
- **Goodput > 10 Mbps:** $(if [ "$(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")" -gt 10 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)

### BBRv2 SLA Compliance
- **P95 RTT < 100ms:** $(if [ "$(jq -r '.sla_compliance.p95_rtt_ms' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")" -lt 100 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)
- **Loss Rate < 5%:** $(if [ "$(jq -r '.sla_compliance.loss_rate_percent' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")" -lt 5 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)
- **Goodput > 10 Mbps:** $(if [ "$(jq -r '.sla_compliance.goodput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")" -gt 10 ]; then echo "âœ… PASS"; else echo "âŒ FAIL"; fi)

## Conclusion

$(if [ "$(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_bbrv2/metrics.json" 2>/dev/null || echo "0")" -gt "$(jq -r '.performance_metrics.throughput_mbps' "${OUTPUT_DIR}/regression_cubic/metrics.json" 2>/dev/null || echo "0")" ]; then echo "BBRv2 shows improved performance over CUBIC in this regression test."; else echo "CUBIC shows better performance than BBRv2 in this regression test."; fi)

## Files Structure

\`\`\`
${OUTPUT_DIR}/
â”œâ”€â”€ regression_cubic/
â”‚   â”œâ”€â”€ server.log
â”‚   â”œâ”€â”€ client.log
â”‚   â”œâ”€â”€ server-qlog/
â”‚   â”œâ”€â”€ client-qlog/
â”‚   â””â”€â”€ metrics.json
â”œâ”€â”€ regression_bbrv2/
â”‚   â”œâ”€â”€ server.log
â”‚   â”œâ”€â”€ client.log
â”‚   â”œâ”€â”€ server-qlog/
â”‚   â”œâ”€â”€ client-qlog/
â”‚   â””â”€â”€ metrics.json
â”œâ”€â”€ regression_comparison.json
â””â”€â”€ regression_test_report.md
\`\`\`

EOF
    
    print_color $GREEN "âœ… Report generated: $report_file"
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ° ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ¸
show_help() {
    cat << EOF
QUIC Regression Test Script
==========================

Usage: $0 [OPTIONS]

OPTIONS:
  --duration SECONDS   - Test duration per algorithm (default: 60)
  --output DIR         - Output directory (default: ./regression-results)
  --cleanup            - Clean up previous results before running
  --analysis-only      - Only analyze existing results
  --help               - Show this help

EXAMPLES:
  $0                    # Run regression tests with default settings
  $0 --duration 120     # Run 120-second tests
  $0 --cleanup          # Clean and run tests
  $0 --analysis-only    # Analyze existing results

EOF
}

# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°
main() {
    local cleanup_flag=false
    local analysis_only=false
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
    while [[ $# -gt 0 ]]; do
        case $1 in
            --duration)
                TEST_DURATION=$2
                shift 2
                ;;
            --output)
                OUTPUT_DIR=$2
                shift 2
                ;;
            --cleanup)
                cleanup_flag=true
                shift
                ;;
            --analysis-only)
                analysis_only=true
                shift
                ;;
            --help|-h)
                show_help
                exit 0
                ;;
            *)
                print_color $RED "âŒ Unknown option: $1"
                show_help
                exit 1
                ;;
        esac
    done
    
    print_color $GREEN "ğŸ§ª QUIC Regression Test Suite"
    print_color $GREEN "============================="
    print_color $BLUE "Algorithms: ${ALGORITHMS[*]}"
    print_color $BLUE "Duration: ${TEST_DURATION}s per algorithm"
    print_color $BLUE "Output: ${OUTPUT_DIR}"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    check_dependencies
    
    # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    if [ "$cleanup_flag" = true ]; then
        print_color $BLUE "ğŸ§¹ Cleaning up previous results..."
        rm -rf "$OUTPUT_DIR" 2>/dev/null || true
    fi
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    mkdir -p "$OUTPUT_DIR"
    
    if [ "$analysis_only" = true ]; then
        compare_results
        generate_report
        return
    fi
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ°
    for algorithm in "${ALGORITHMS[@]}"; do
        print_color $YELLOW "ğŸ”„ Testing algorithm: ${algorithm}"
        
        run_regression_test $algorithm
        
        # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸
        extract_metrics "${OUTPUT_DIR}/regression_${algorithm}" $algorithm
    done
    
    # Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
    compare_results
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚
    generate_report
    
    print_color $GREEN "ğŸ‰ Regression testing completed!"
    print_color $BLUE "ğŸ“ Results available in: ${OUTPUT_DIR}/"
}

# Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ
main "$@"

